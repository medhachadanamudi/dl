{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KY4js3aX7no6"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HweuaIooIizu"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORo9oGPiA8k7"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjfRnVN12JWF"
      },
      "source": [
        "# ** Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1Fl0K9TVJ50"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92GABWQa1eYT"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca4Hv2sT4lt-"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k25m_dVm6-bP"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHnTmrSwNg6S"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLsPGJiuxRrK"
      },
      "source": [
        "#** Mount drive and link your folder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhZoiRBoqnju"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "!ls /mydrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "useG4r6nOn9h"
      },
      "source": [
        "# ** Clone the tensorflow models git repository & Install TensorFlow Object Detection API**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv3C8-s0koQU"
      },
      "source": [
        "# clone the tensorflow models on the colab cloud vm\n",
        "!git clone --q https://github.com/tensorflow/models.git\n",
        "\n",
        "#navigate to /models/research folder to compile protos\n",
        "%cd models/research\n",
        "\n",
        "# Compile protos.\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# Install TensorFlow Object Detection API.\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install .\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D1UNW7c9O-I"
      },
      "source": [
        "# **7) Test the model builder**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St1r_0-w9jqI"
      },
      "source": [
        "# testing the model builder\n",
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2naqsZBA9WW4"
      },
      "source": [
        "# **8) Navigate to /mydrive/customTF2/data/ and Unzip the *images.zip* and *annotations.zip* files into the *data* folder**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1UT5_rrTw6e"
      },
      "source": [
        "%cd /mydrive/customTF2/data/\n",
        "\n",
        "# unzip the datasets and their contents so that they are now in /mydrive/customTF2/data/ folder\n",
        "!unzip /mydrive/customTF2/images.zip -d .\n",
        "!unzip /mydrive/customTF2/annotations.zip -d ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYUW7UZejKFb"
      },
      "source": [
        "# **9) Create test_labels & train_labels**\n",
        "Current working directory is /mydrive/customTF2/data/\n",
        "\n",
        "Divide annotations into test_labels(20%) and train_labels(80%)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoyMt_vssl1j"
      },
      "source": [
        "#creating two dir for training and testing\n",
        "!mkdir test_labels train_labels\n",
        "\n",
        "# lists the files inside 'annotations' in a random order (not really random, by their hash value instead)\n",
        "# Moves the first 274/1370 labels (20% of the labels) to the testing dir: `test_labels`\n",
        "!ls annotations/* | sort -R | head -274 | xargs -I{} mv {} test_labels/\n",
        "\n",
        "\n",
        "# Moves the rest of the labels ( 1096 labels ) to the training dir: `train_labels`\n",
        "!ls annotations/* | xargs -I{} mv {} train_labels/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH67M2M12s3n"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyGisGxK4ag0"
      },
      "source": [
        "#adjusted from: https://github.com/datitran/raccoon_dataset\n",
        "def xml_to_csv(path):\n",
        "  classes_names = []\n",
        "  xml_list = []\n",
        "\n",
        "  for xml_file in glob.glob(path + '/*.xml'):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    for member in root.findall('object'):\n",
        "      classes_names.append(member[0].text)\n",
        "      value = (root.find('filename').text  ,   \n",
        "               int(root.find('size')[0].text),\n",
        "               int(root.find('size')[1].text),\n",
        "               member[0].text,\n",
        "               int(member[4][0].text),\n",
        "               int(member[4][1].text),\n",
        "               int(member[4][2].text),\n",
        "               int(member[4][3].text))\n",
        "      xml_list.append(value)\n",
        "  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "  xml_df = pd.DataFrame(xml_list, columns=column_name) \n",
        "  classes_names = list(set(classes_names))\n",
        "  classes_names.sort()\n",
        "  return xml_df, classes_names\n",
        "\n",
        "for label_path in ['train_labels', 'test_labels']:\n",
        "  image_path = os.path.join(os.getcwd(), label_path)\n",
        "  xml_df, classes = xml_to_csv(label_path)\n",
        "  xml_df.to_csv(f'{label_path}.csv', index=None)\n",
        "  print(f'Successfully converted {label_path} xml to csv.')\n",
        "\n",
        "label_map_path = os.path.join(\"label_map.pbtxt\")\n",
        "pbtxt_content = \"\"\n",
        "\n",
        "for i, class_name in enumerate(classes):\n",
        "    pbtxt_content = (\n",
        "        pbtxt_content\n",
        "        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n}}\\n\\n\".format(i + 1, class_name)\n",
        "    )\n",
        "pbtxt_content = pbtxt_content.strip()\n",
        "with open(label_map_path, \"w\") as f:\n",
        "    f.write(pbtxt_content)\n",
        "    print('Successfully created label_map.pbtxt ')   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tblFU-i495qr"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET4SXdtYUIjZ"
      },
      "source": [
        "#Usage:  \n",
        "#!python generate_tfrecord.py output.csv output_pb.txt /path/to/images output.tfrecords\n",
        "\n",
        "#For train.record\n",
        "!python /mydrive/customTF2/generate_tfrecord.py train_labels.csv  label_map.pbtxt images/ train.record\n",
        "\n",
        "#For test.record\n",
        "!python /mydrive/customTF2/generate_tfrecord.py test_labels.csv  label_map.pbtxt images/ test.record\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwWh49ClaBeD"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obEW7RNEcowc"
      },
      "source": [
        "#Download the pre-trained model ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz into the data folder & unzip it.\n",
        "\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "!tar -xzvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS-xqg02X9Ro"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze7ewaO3c545"
      },
      "source": [
        "#copy the edited config file from the configs/tf2 directory to the data/ folder in your drive\n",
        "\n",
        "!cp /content/models/research/object_detection/configs/tf2/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config /mydrive/customTF2/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88pz7JpMNRRK"
      },
      "source": [
        "# **14) Load Tensorboard**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-86d0AXNQp7"
      },
      "source": [
        "#load tensorboard\n",
        "\n",
        "%load_ext tensorboard         \n",
        "%tensorboard --logdir '/content/gdrive/MyDrive/customTF2/training'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlzGrIfdAKj9"
      },
      "source": [
        "# **15) Train the model** \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPmZ2cv17jIj"
      },
      "source": [
        "## Navigate to the ***object_detection*** folder in colab vm\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-40iq_0ZMgfL"
      },
      "source": [
        "%cd /content/models/research/object_detection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pjP3TuBMjli"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LS0SBCgRuox"
      },
      "source": [
        "# Run the command below from the content/models/research/object_detection directory\n",
        "\"\"\"\n",
        "PIPELINE_CONFIG_PATH=path/to/pipeline.config\n",
        "MODEL_DIR=path to training checkpoints directory\n",
        "NUM_TRAIN_STEPS=50000\n",
        "SAMPLE_1_OF_N_EVAL_EXAMPLES=1\n",
        "\n",
        "python model_main_tf2.py -- \\\n",
        "  --model_dir=$MODEL_DIR --num_train_steps=$NUM_TRAIN_STEPS \\\n",
        "  --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \\\n",
        "  --pipeline_config_path=$PIPELINE_CONFIG_PATH \\\n",
        "  --alsologtostderr\n",
        "\"\"\"\n",
        "\n",
        "!python model_main_tf2.py --pipeline_config_path=/mydrive/customTF2/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config --model_dir=/mydrive/customTF2/training --alsologtostderr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xzZdwx7kgOV1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KoZ6zVpDmtT"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHAeEbZE_sZ-"
      },
      "source": [
        "# Run the command below from the content/models/research/object_detection directory\n",
        "\"\"\"\n",
        "PIPELINE_CONFIG_PATH=path/to/pipeline.config\n",
        "MODEL_DIR=path to training checkpoints directory\n",
        "CHECKPOINT_DIR=${MODEL_DIR}\n",
        "NUM_TRAIN_STEPS=50000\n",
        "SAMPLE_1_OF_N_EVAL_EXAMPLES=1\n",
        "\n",
        "python model_main_tf2.py -- \\\n",
        "  --model_dir=$MODEL_DIR --num_train_steps=$NUM_TRAIN_STEPS \\\n",
        "  --checkpoint_dir=${CHECKPOINT_DIR} \\\n",
        "  --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \\\n",
        "  --pipeline_config_path=$PIPELINE_CONFIG_PATH \\\n",
        "  --alsologtostderr\n",
        "\"\"\"\n",
        "\n",
        "!python model_main_tf2.py --pipeline_config_path=/mydrive/customTF2/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config --model_dir=/mydrive/customTF2/training/ --checkpoint_dir=/mydrive/customTF2/training/ --alsologtostderr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-rHe_AzNSs8"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxn-FtdtpsTx"
      },
      "source": [
        "# **16) Test your trained model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_tTeYM5ScU1"
      },
      "source": [
        "## Export inference graph\n",
        "\n",
        "Current working directory is /content/models/research/object_detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB4JHHqHSoiq"
      },
      "source": [
        "##Export inference graph\n",
        "!python exporter_main_v2.py --trained_checkpoint_dir=/mydrive/customTF2/training --pipeline_config_path=/content/gdrive/MyDrive/customTF2/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config --output_directory /mydrive/customTF2/data/inference_graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIfZPBYbSgkZ"
      },
      "source": [
        "## Test your trained Object Detection model on images\n",
        "\n",
        "Current working directory is /content/models/research/object_detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVHHs6vNJEVy"
      },
      "source": [
        "# Different font-type for labels text.(This step is optional)\n",
        "!wget https://freefontsdownload.net/download/160187/arial.zip\n",
        "!unzip arial.zip -d .\n",
        "\n",
        "%cd utils/\n",
        "!sed -i \"s/font = ImageFont.truetype('arial.ttf', 24)/font = ImageFont.truetype('arial.ttf', 50)/\" visualization_utils.py\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Iq2Wq3SKtOs"
      },
      "source": [
        "#Loading the saved_model\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "IMAGE_SIZE = (12, 8) # Output display size as you want\n",
        "import matplotlib.pyplot as plt\n",
        "PATH_TO_SAVED_MODEL=\"/mydrive/customTF2/data/inference_graph/saved_model\"\n",
        "print('Loading model...', end='')\n",
        "\n",
        "# Load saved model and build the detection function\n",
        "detect_fn=tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "print('Done!')\n",
        "\n",
        "#Loading the label_map\n",
        "category_index=label_map_util.create_category_index_from_labelmap(\"/mydrive/customTF2/data/label_map.pbtxt\",use_display_name=True)\n",
        "#category_index=label_map_util.create_category_index_from_labelmap([path_to_label_map],use_display_name=True)\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "image_path = \"/mydrive/mask_test_images/image1.jpg\"\n",
        "#print('Running inference for {}... '.format(image_path), end='')\n",
        "\n",
        "image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "input_tensor = tf.convert_to_tensor(image_np)\n",
        "# The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "# All outputs are batches tensors.\n",
        "# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "# We're only interested in the first num_detections.\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_with_detections,\n",
        "      detections['detection_boxes'],\n",
        "      detections['detection_classes'],\n",
        "      detections['detection_scores'],\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=.4, # Adjust this value to set the minimum probability boxes to be classified as True\n",
        "      agnostic_mode=False)\n",
        "%matplotlib inline\n",
        "plt.figure(figsize=IMAGE_SIZE, dpi=200)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(image_np_with_detections)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RizqBXZrOYon"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afZcMjuiLEUi"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wlA4OSmiC-t"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CePE-vSvisXj"
      },
      "source": [
        "# ðŸ––"
      ]
    }
  ]
}